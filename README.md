![text representation](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_sl0zFWi7_DNe07lXtdYC3KJ-J5OS4AnJTEUUtKJYRGkEmBtHFA2Wc2p58q5trmP8pN8&usqp=CAU)
# Text-Representation
NLP techniques apply "machines" to process natural language used by human.
  
We need to translate human langage to machine language!
  
- What human generate:  
![human](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR-uaUgkTjRfpvxNGQfFtXq1aJ1FFdM8ZmdBtk0IK3b5AgphbrIBpE0V3yzpqUdDrT6su4&usqp=CAU)

- What machine can read:  
![machine](https://miro.medium.com/v2/resize:fit:960/1*_kbFlq2YypdZUZbdkwjq0g.jpeg)


[Note] This is an essential step for further text processing tasks, such as sentiment analysis, text similairty, clustering, etc. 

 - # Word representation
   - **One-hot encoding**
   - **Bag-of-Words (BOW)**
   - **Term Frequency-Inverse Document Frequency (TF-IDF)**
   - **Word Embedding**
     - Word2Vec
     - GloVe
     - FastText
   - **Transformers-based embedding**

 - # Document representation
   - **Bag-of-Words (BOW)**
   - **Term Frequency-Inverse Document Frequency (TF-IDF)**
   - **Topic modeling**
   - **Document embedding**
     - Word embedding aggregation
     - Doc2Vec
   - **Transformers-based embedding**
     
